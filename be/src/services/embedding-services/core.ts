/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ğŸ”® CORE EMBEDDING FUNCTIONS
 *
 * Core embedding generation and similarity functions using OpenAI embeddings.
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */

import { Env } from "@/index";

/**
 * ğŸ”® Generate AI Embedding Vector for Psychological Text
 *
 * Transforms psychological text (excuses, fears, commitments) into a 1536-dimensional
 * vector using OpenAI's text-embedding-ada-002 model. These vectors enable semantic
 * similarity search for pattern recognition and accountability leverage.
 *
 * @param text - Psychological content to vectorize (max 8191 tokens)
 * @param env - Environment with OPENAI_API_KEY
 * @returns 1536-dimensional vector array representing semantic meaning
 *
 * ğŸ’¡ Use Cases:
 * â€¢ "I'm too tired" â†’ [0.123, -0.456, 0.789...]
 * â€¢ Later: "I don't have energy" â†’ Similar vector = Pattern detected!
 */
export async function generateEmbedding(
  text: string,
  env: Env,
): Promise<number[]> {
  try {
    console.log(`ğŸ”® Generating embedding for: "${text.substring(0, 50)}..."`);

    const response = await fetch("https://api.openai.com/v1/embeddings", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "text-embedding-ada-002", // ğŸ¯ 1536 dimensions, $0.0001/1K tokens
        input: text,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI Embedding API error: ${response.status}`);
    }

    const result = await response.json();
    const embedding = result.data[0]?.embedding || [];
    console.log(
      `âœ… Generated ${embedding.length}-dimensional embedding vector`,
    );

    return embedding;
  } catch (error) {
    console.error("ğŸ’¥ Embedding generation failed:", error);
    throw error;
  }
}

/**
 * âš¡ Generate Multiple AI Embeddings in Single Request
 *
 * Efficiently processes multiple psychological texts in one API call for significant
 * cost and latency savings. Perfect for bulk identity data processing or initial
 * memory bank creation.
 *
 * @param texts - Array of psychological content to vectorize (max 2048 items)
 * @param env - Environment with OPENAI_API_KEY
 * @returns Array of 1536-dimensional vectors, maintaining input order
 *
 * ğŸ’° Cost Optimization:
 * â€¢ Single request vs. multiple = ~50% latency reduction
 * â€¢ Batch processing = More efficient token usage
 * â€¢ Ideal for identity table â†’ memory embeddings conversion
 */
export async function generateBatchEmbeddings(
  texts: string[],
  env: Env,
): Promise<number[][]> {
  try {
    console.log(
      `âš¡ Generating batch embeddings for ${texts.length} psychological texts`,
    );

    const response = await fetch("https://api.openai.com/v1/embeddings", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "text-embedding-ada-002", // ğŸ¯ Batch limit: 2048 inputs per request
        input: texts,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI Embedding API error: ${response.status}`);
    }

    const result = await response.json();
    const embeddings = result.data?.map((item: any) => item.embedding) || [];
    console.log(`âœ… Generated ${embeddings.length} embedding vectors in batch`);

    return embeddings;
  } catch (error) {
    console.error("ğŸ’¥ Batch embedding generation failed:", error);
    throw error;
  }
}

/**
 * ğŸ“ Calculate Cosine Similarity Between Two Embedding Vectors
 *
 * Computes semantic similarity between psychological content using vector math.
 * Returns score from -1 (opposite) to 1 (identical), with 0 being unrelated.
 * Used for local similarity computation without database queries.
 *
 * @param vecA - First embedding vector (1536 dimensions)
 * @param vecB - Second embedding vector (1536 dimensions)
 * @returns Similarity score: 1 = identical, 0 = unrelated, -1 = opposite
 *
 * ğŸ§® Mathematical Process:
 * 1. Dot Product: Sum of element-wise multiplication
 * 2. Vector Norms: Magnitude of each vector
 * 3. Cosine Similarity: dot(A,B) / (||A|| * ||B||)
 *
 * ğŸ’¡ Psychological Interpretation:
 * â€¢ 0.9+ = "You said the exact same thing before"
 * â€¢ 0.7+ = "This sounds familiar to your past pattern"
 * â€¢ 0.5+ = "Similar theme to something you've mentioned"
 */
export function cosineSimilarity(vecA: number[], vecB: number[]): number {
  if (vecA.length !== vecB.length) {
    throw new Error(`Vector length mismatch: ${vecA.length} vs ${vecB.length}`);
  }

  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  // ğŸ§® Compute dot product and vector magnitudes in single pass
  for (let i = 0; i < vecA.length; i++) {
    const a = vecA[i] || 0;
    const b = vecB[i] || 0;

    dotProduct += a * b;
    normA += a * a;
    normB += b * b;
  }

  // ğŸ“ Return cosine similarity score
  const similarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
  return isNaN(similarity) ? 0 : similarity;
}

/**
 * ğŸ¯ Find Similar Memories from Local Memory Array
 *
 * Performs client-side similarity search across an array of memory embeddings.
 * Useful when you already have memories loaded and want to avoid database queries.
 * Returns ranked results above similarity threshold.
 *
 * @param queryEmbedding - Current behavior/content embedding to match
 * @param memories - Array of memory objects with embeddings and content
 * @param threshold - Minimum similarity score to include (default: 0.8)
 * @returns Ranked array of similar memories with similarity scores
 *
 * ğŸ” Perfect for:
 * â€¢ Batch processing already-loaded memories
 * â€¢ Real-time pattern matching during calls
 * â€¢ Local similarity computation without DB roundtrips
 * â€¢ Custom filtering and ranking logic
 *
 * ğŸ“Š Processing Steps:
 * 1. Calculate similarity score for each memory
 * 2. Filter results above threshold
 * 3. Sort by similarity (highest first)
 * 4. Return ranked matches for accountability use
 */
export function findSimilarMemories(
  queryEmbedding: number[],
  memories: Array<{ embedding: number[]; text_content: string; id: string }>,
  threshold = 0.8,
): Array<{ id: string; text_content: string; similarity: number }> {
  console.log(
    `ğŸ¯ Analyzing ${memories.length} memories locally (threshold: ${threshold})`,
  );

  const results = memories
    .map((memory) => ({
      id: memory.id,
      text_content: memory.text_content,
      similarity: cosineSimilarity(queryEmbedding, memory.embedding),
    }))
    .filter((result) => result.similarity >= threshold)
    .sort((a, b) => b.similarity - a.similarity);

  console.log(`âœ… Found ${results.length} similar memories above threshold`);
  return results;
}
